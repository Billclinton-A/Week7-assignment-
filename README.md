Assignment Parts
Part 1: Theoretical Understanding (30%)

Short Answer Questions

Define algorithmic bias with two examples.

Difference between transparency and explainability in AI.

GDPR’s impact on AI development in the EU.

Ethical Principles Matching

Justice – Fair distribution of AI benefits and risks

Non-maleficence – Ensuring AI does not harm individuals or society

Autonomy – Respecting users’ right to control their data and decisions

Sustainability – Designing AI to be environmentally friendly

Part 2: Case Study Analysis (40%)

Case 1: Biased Hiring Tool

Identify sources of bias (training data, model design)

Propose three fixes

Suggest metrics to evaluate fairness

Case 2: Facial Recognition in Policing

Discuss ethical risks (e.g., wrongful arrests, privacy violations)

Recommend policies for responsible deployment

Part 3: Practical Audit (25%)

Dataset: COMPAS Recidivism Dataset

Tasks:

Use Python and AI Fairness 360 to analyze racial bias

Visualize disparities (e.g., false positive rates)

Submit a 300-word report with findings and remediation steps

Part 4: Ethical Reflection (5%)

Reflect on a personal project (past or future)

Explain how it will adhere to ethical AI principles

Tools & Resources

Python Libraries: AI Fairness 360, Pandas, Matplotlib

Datasets: COMPAS (provided), ProPublica’s Analysis

Frameworks: EU Ethics Guidelines for Trustworthy AI

Grading Rubric
Criteria	Weight
Theoretical Accuracy	30%
Case Study Depth & Solutions	40%
Technical Audit Execution	25%
Reflection & Creativity	5%
How to Run the Code

Install dependencies:

pip install aif360 pandas matplotlib


Open AI_Ethics_Audit.ipynb in Jupyter Notebook or Google Colab.

Load the COMPAS dataset.

Execute cells sequentially to reproduce visualizations and fairness metrics.

Bonus Task (Extra 10%)

Draft a 1-page guideline for ethical AI use in healthcare, including:

Patient consent protocols

Bias mitigation strategies

Transparency requirements
